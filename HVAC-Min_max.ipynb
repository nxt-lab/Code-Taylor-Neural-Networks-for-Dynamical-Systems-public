{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d5b8ba-ca76-4170-9dfd-c1a352d2b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc07a94-13ca-4945-934b-dbe92fcd5175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef71b7d-6549-433f-8192-e15d3643bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "data = pd.read_csv(\"data-B90102-30m.csv\")\n",
    "room = data[\"room_temp\"]\n",
    "airflow = data[\"airflow_current\"]\n",
    "supply = data[\"supply_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e541ea-d8da-4691-a21f-7b2b1047d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta =  np.array(room[start:-1]) - np.array(room[start-1:-2])\n",
    "delta_supply = np.array(supply[start+1:]) - np.array(supply[start:-1])\n",
    "delta_air = np.array(airflow[start+1:]) - np.array(airflow[start:-1])\n",
    "\n",
    "temp_current = np.array(room[start:-1]).reshape(-1,1)\n",
    "temp = np.array(room[start:-1]).reshape(-1,1)\n",
    "output = np.array(room[start+1:]).reshape(-1,1)\n",
    "air = np.array(airflow[start+1:]).reshape(-1,1)\n",
    "supply = np.array(supply[start+1:]).reshape(-1,1)\n",
    "\n",
    "air_origin = torch.tensor(air).to(device).reshape(-1,1).float()\n",
    "supply_origin = torch.tensor(supply).to(device).reshape(-1,1).float()\n",
    "temp_origin = torch.tensor(temp).to(device).reshape(-1,1).float()\n",
    "output_origin = torch.tensor(output).to(device).reshape(-1,1).float()\n",
    "temp_current = torch.tensor(temp_current).to(device).reshape(-1,1).float()\n",
    "\n",
    "delta = torch.tensor(delta).reshape(-1,1).float().to(device)/(max(temp_origin) - min(temp_origin))\n",
    "delta_supply = torch.tensor(delta_supply).reshape(-1,1).float().to(device)/(max(supply_origin) - min(supply_origin))\n",
    "delta_air = torch.tensor(delta_air).reshape(-1,1).float().to(device)/(max(air_origin)- min(air_origin))\n",
    "\n",
    "delta = torch.concat((delta, delta_supply, delta_air), dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f13bd5-dd78-4615-b4e4-c1093f4c4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "air = (air_origin - min(air_origin))/(max(air_origin)- min(air_origin))\n",
    "air = air.requires_grad_(True)\n",
    "supply = (supply_origin - min(supply_origin))/(max(supply_origin) - min(supply_origin))\n",
    "supply = supply.requires_grad_(True)\n",
    "temp = (temp_origin - min(temp_origin))/(max(temp_origin) - min(temp_origin))\n",
    "temp = temp.requires_grad_(True)\n",
    "output = (output - min(output))/(max(output) - min(output))\n",
    "output = torch.tensor(output).reshape(-1,1).float().to(device)\n",
    "temp_current = (temp_current - min(temp_origin))/(max(temp_origin) - min(temp_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe46b52-7850-431f-a81a-4f15205e8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train(N: int, N_end: int, temp_current: torch.Tensor, temp: torch.Tensor, supply: torch.Tensor, air: torch.Tensor, output: torch.Tensor, delta: torch.Tensor):\n",
    "    temp_current_train = temp_current[N:N_end]\n",
    "    temp_train = temp[N:N_end]\n",
    "    supply_train = supply[N:N_end]\n",
    "    air_train = air[N:N_end]\n",
    "    output_train = output[N:N_end]\n",
    "    # Delta delta\n",
    "    delta_train = delta[N:N_end].requires_grad_(True)\n",
    "    return temp_current_train, temp_train, supply_train, air_train, output_train, delta_train\n",
    "\n",
    "def data_test(N: int, end: int, temp_current: torch.Tensor, temp: torch.Tensor, supply: torch.Tensor, air: torch.Tensor, output: torch.Tensor, delta: torch.Tensor):\n",
    "    temp_current_test = temp_current[N:end]\n",
    "    temp_test = temp[N:end]\n",
    "    supply_test = supply[N:end]\n",
    "    air_test = air[N:end]\n",
    "    output_test = output[N:end]\n",
    "    delta_test = delta[N:end]\n",
    "    return temp_current_test, temp_test, supply_test, air_test, output_test, delta_test\n",
    "\n",
    "def data_val(N: int, end: int, temp_current: torch.Tensor, temp: torch.Tensor, supply: torch.Tensor, air: torch.Tensor, output: torch.Tensor, delta: torch.Tensor):\n",
    "    temp_current_val = temp_current[N:end]\n",
    "    temp_val = temp[N:end]\n",
    "    supply_val = supply[N:end]\n",
    "    air_val = air[N:end]\n",
    "    output_val = output[N:end]\n",
    "    delta_val = delta[N:end]\n",
    "    return temp_current_val, temp_val, supply_val, air_val, output_val, delta_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533014d-c12c-4ab1-8071-2645172f9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialParameterization(nn.Module):\n",
    "    def forward(self, X):\n",
    "        return torch.exp(X)\n",
    "\n",
    "class Max(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Max, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.max(x, dim=-1, keepdim=True)[0]\n",
    "\n",
    "class Min(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Min, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.min(x, dim=-1)[0]\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.fc1_1 = nn.Linear(1, 4)  \n",
    "        self.fc1_2 = nn.Linear(1, 4)\n",
    "        self.fc1_3 = nn.Linear(1, 4)\n",
    "        self.fc2 = nn.ModuleList([Max() for _ in range(2)])  \n",
    "        self.fc3 = Min()  \n",
    "        parametrize.register_parametrization(self.fc1_2, \"weight\", ExponentialParameterization())\n",
    "    \n",
    "    def forward(self, x, y, z):\n",
    "        x_1 = self.fc1_1(x)  \n",
    "        y_1 = self.fc1_2(y)\n",
    "        z_1 = self.fc1_3(z)\n",
    "        x = x_1 + y_1 + z_1\n",
    "        split_size = x.size(1) // 2\n",
    "        x_splits = [x[:, i*split_size:(i+1)*split_size] for i in range(2)]\n",
    "        x = torch.cat([fc(split) for fc, split in zip(self.fc2, x_splits)], dim=-1)\n",
    "        output = self.fc3(x).reshape(-1, 1)\n",
    "        return output\n",
    "\n",
    "net = CustomNet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfa122-c13b-49ca-9494-8c2fd307f391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 25000\n",
    "patience = 1000\n",
    "threshold = 1e-15\n",
    "decay_factor = 1.0  \n",
    "decay_step_size = 1000  \n",
    "N_start, N_end = 360, 540\n",
    "Ns_test, Ne_test = 950, 1050\n",
    "Ns_val, Ne_val = 800, 900\n",
    "\n",
    "temp_current_train, temp_train, supply_train, air_train, output_train, delta_train = data_train(N_start, N_end, temp_current, temp, supply, air, output, delta)\n",
    "temp_current_test, temp_test, supply_test, air_test, output_test, delta_test = data_test(Ns_test, Ne_test, temp_current, temp, supply, air, output, delta)\n",
    "temp_current_val, temp_val, supply_val, air_val, output_val, delta_val = data_val(Ns_val, Ne_val, temp_current, temp, supply, air, output, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ccf35-afbb-4e4b-87c9-0711bd8977ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25000], Loss: 1.118266106\n",
      "Epoch [5001/25000], Loss: 0.000911587\n",
      "Epoch [10001/25000], Loss: 0.000366998\n",
      "Epoch [15001/25000], Loss: 0.000246891\n",
      "Epoch [20001/25000], Loss: 0.000238011\n",
      "0.0002765938\n",
      "Epoch [1/25000], Loss: 1.238411546\n",
      "Epoch [5001/25000], Loss: 0.001082048\n",
      "Epoch [10001/25000], Loss: 0.000323510\n",
      "Epoch [15001/25000], Loss: 0.000238821\n",
      "Epoch [20001/25000], Loss: 0.000238065\n",
      "Epoch [1/25000], Loss: 0.166883275\n",
      "Epoch [5001/25000], Loss: 0.000276335\n",
      "Epoch [10001/25000], Loss: 0.000267752\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.275520980\n",
      "Epoch [5001/25000], Loss: 0.000267438\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.548583090\n",
      "Epoch [5001/25000], Loss: 0.000265936\n",
      "Epoch [10001/25000], Loss: 0.000269856\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000279061\n",
      "Epoch [1/25000], Loss: 0.477411836\n",
      "Epoch [5001/25000], Loss: 0.000280572\n",
      "Epoch [10001/25000], Loss: 0.000266438\n",
      "Epoch [15001/25000], Loss: 0.000265905\n",
      "Epoch [20001/25000], Loss: 0.000265867\n",
      "Epoch [1/25000], Loss: 0.166586071\n",
      "Epoch [5001/25000], Loss: 0.000269606\n",
      "Epoch [10001/25000], Loss: 0.000266002\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.211227849\n",
      "Epoch [5001/25000], Loss: 0.000262803\n",
      "Epoch [10001/25000], Loss: 0.000265877\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.900369883\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000266189\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.229502246\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265871\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 2.296340704\n",
      "Epoch [5001/25000], Loss: 0.000265630\n",
      "Epoch [10001/25000], Loss: 0.000262910\n",
      "Epoch [15001/25000], Loss: 0.000262773\n",
      "Epoch [20001/25000], Loss: 0.000267211\n",
      "Epoch [1/25000], Loss: 1.654689908\n",
      "Epoch [5001/25000], Loss: 0.000268812\n",
      "Epoch [10001/25000], Loss: 0.000265869\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.949036360\n",
      "Epoch [5001/25000], Loss: 0.000282672\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.596685827\n",
      "Epoch [5001/25000], Loss: 0.000263136\n",
      "Epoch [10001/25000], Loss: 0.000263237\n",
      "Epoch [15001/25000], Loss: 0.000263136\n",
      "Epoch [20001/25000], Loss: 0.000263200\n",
      "Epoch [1/25000], Loss: 0.220803201\n",
      "Epoch [5001/25000], Loss: 0.000265865\n",
      "Epoch [10001/25000], Loss: 0.000265867\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.963415384\n",
      "Epoch [5001/25000], Loss: 0.000266657\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000552916\n",
      "Epoch [20001/25000], Loss: 0.000265863\n",
      "Epoch [1/25000], Loss: 1.926701546\n",
      "Epoch [5001/25000], Loss: 0.000266384\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.001364711\n",
      "Epoch [1/25000], Loss: 1.227095723\n",
      "Epoch [5001/25000], Loss: 0.000265953\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 1.038633466\n",
      "Epoch [5001/25000], Loss: 0.000265865\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.270732731\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.988641322\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265914\n",
      "Epoch [15001/25000], Loss: 0.000265892\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 1.877936482\n",
      "Epoch [5001/25000], Loss: 0.000265877\n",
      "Epoch [10001/25000], Loss: 0.000314351\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.224757746\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265869\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.303766251\n",
      "Epoch [5001/25000], Loss: 0.000263136\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000268869\n",
      "Epoch [1/25000], Loss: 0.563740194\n",
      "Epoch [5001/25000], Loss: 0.000240663\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.437608480\n",
      "Epoch [5001/25000], Loss: 0.000265911\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000366581\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.759023905\n",
      "Epoch [5001/25000], Loss: 0.000266048\n",
      "Epoch [10001/25000], Loss: 0.000265878\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.334042996\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265867\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.762759566\n",
      "Epoch [5001/25000], Loss: 0.000301101\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.625440478\n",
      "Epoch [5001/25000], Loss: 0.000265980\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265866\n",
      "Epoch [1/25000], Loss: 0.104897819\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000268669\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.436689168\n",
      "Epoch [5001/25000], Loss: 0.000265869\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000266043\n",
      "Epoch [1/25000], Loss: 0.182670340\n",
      "Epoch [5001/25000], Loss: 0.000265927\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000303223\n",
      "Epoch [1/25000], Loss: 0.117227539\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000267819\n",
      "Epoch [15001/25000], Loss: 0.000280880\n",
      "Epoch [20001/25000], Loss: 0.000265870\n",
      "Epoch [1/25000], Loss: 1.526126146\n",
      "Epoch [5001/25000], Loss: 0.000712479\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.666180730\n",
      "Epoch [5001/25000], Loss: 0.000265866\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.645149410\n",
      "Epoch [5001/25000], Loss: 0.000265865\n",
      "Epoch [10001/25000], Loss: 0.000329063\n",
      "Epoch [15001/25000], Loss: 0.000266376\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.201218128\n",
      "Epoch [5001/25000], Loss: 0.000453501\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000285635\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.492580295\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.089701571\n",
      "Epoch [5001/25000], Loss: 0.000527959\n",
      "Epoch [10001/25000], Loss: 0.000265886\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 1.056972742\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.927214921\n",
      "Epoch [5001/25000], Loss: 0.000265865\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000268999\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.040439740\n",
      "Epoch [5001/25000], Loss: 0.000265866\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 4.195425034\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000287464\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.131783962\n",
      "Epoch [5001/25000], Loss: 0.000374220\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265894\n",
      "Epoch [1/25000], Loss: 1.633179784\n",
      "Epoch [5001/25000], Loss: 0.000266667\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.001203991\n",
      "Epoch [1/25000], Loss: 0.906071842\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000274034\n",
      "Epoch [1/25000], Loss: 1.511553645\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000829033\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.117437787\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000280664\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.373397082\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Early stopping due to no significant improvement.\n"
     ]
    }
   ],
   "source": [
    "learning = np.arange(0.001, 0.1, 0.002)\n",
    "num_test = 1\n",
    "current_mse_score = 0\n",
    "mse = []\n",
    "mse.append(10.0)\n",
    "prev_loss = 10\n",
    "for lr in learning:\n",
    "    net = CustomNet().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.9)  # Adjust step_size and gamma as needed\n",
    "    criterion = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(temp_train, supply_train, air_train)\n",
    "        t_next = output\n",
    "        loss = criterion(t_next, output_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  \n",
    "        \n",
    "        if epoch % 5000 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.9f}')\n",
    "            \n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            no_improvement_counter += 1\n",
    "        else:\n",
    "            no_improvement_counter = 0  \n",
    "                \n",
    "        prev_loss = loss.item()   \n",
    "        if no_improvement_counter >= patience:\n",
    "            print(\"Early stopping due to no significant improvement.\")\n",
    "            break\n",
    "        if loss.item() < 0.00000063711:\n",
    "            print(\"Loss function too small\")\n",
    "            break\n",
    "    \n",
    "    t_next = net(temp_val, supply_val, air_val)\n",
    "    current_mse_score = mean_squared_error(output_val.to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    if current_mse_score < min(mse):\n",
    "        torch.save(net.state_dict(), f\"model_Min_Max_5_min.pth\")\n",
    "        mse.append(current_mse_score)\n",
    "        print(current_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f04277-8ebb-45c8-a929-52314cc676a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9425655397929681,\n",
       " 0.8330258120007011,\n",
       " 0.694461471469566,\n",
       " 0.5431712326914875,\n",
       " 0.3991854542129072,\n",
       " 0.25755559329718103,\n",
       " 0.13180816373670023]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_predict=7\n",
    "r2_loop = []\n",
    "mse_loop = []\n",
    "loaded_model = CustomNet().to(device)\n",
    "model_path = f\"model_Min_Max_5_min.pth\"\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "loaded_model.eval()\n",
    "\n",
    "t_next = loaded_model(temp_test[0:-num_predict], supply_test[0:-num_predict], air_test[0:-num_predict])\n",
    "r2 = r2_score(output_test[0:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "mse = mean_squared_error(output_test[0:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "r2_loop.append(r2)\n",
    "mse_loop.append(mse)\n",
    "for i in list(range(1, num_predict)):\n",
    "    t_next = loaded_model(t_next, supply_test[i:i-num_predict], air_test[i:i-num_predict])\n",
    "    r2 = r2_score(output_test[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    mse = mean_squared_error(output_test[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    mse_loop.append(mse)\n",
    "r2_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3267e7b4-738a-4b5a-8d08-5a93beb7283c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21817884],\n",
       "       [0.36737227],\n",
       "       [0.492254  ],\n",
       "       [0.59620917],\n",
       "       [0.6776514 ],\n",
       "       [0.7470846 ],\n",
       "       [0.80182767]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mse_loop).flatten().reshape(-1, 1)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31f6cf-bf54-46c3-899e-a5212e15cf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
