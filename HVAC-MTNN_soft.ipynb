{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5b8ba-ca76-4170-9dfd-c1a352d2b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc9eca-69f7-4633-9688-dd4b60ad13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "data = pd.read_csv(\"data-B90102-30m.csv\")\n",
    "room = data[\"room_temp\"]\n",
    "airflow = data[\"airflow_cur\"]\n",
    "supply = data[\"supply_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1dd871-417d-4678-8026-570cfe54cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta =  np.array(room[start:-1]) - np.array(room[start-1:-2])\n",
    "delta_supply = np.array(supply[start+1:]) - np.array(supply[start:-1])\n",
    "delta_air = np.array(airflow[start+1:]) - np.array(airflow[start:-1])\n",
    "\n",
    "temp_cur = np.array(room[start:-1]).reshape(-1,1)\n",
    "temp = np.array(room[start-1:-1-1]).reshape(-1,1)\n",
    "output = np.array(room[start+1:]).reshape(-1,1)\n",
    "air = np.array(airflow[start:-1]).reshape(-1,1)\n",
    "supply = np.array(supply[start:-1]).reshape(-1,1)\n",
    "\n",
    "air_origin = torch.tensor(air).to(device).reshape(-1,1).float()\n",
    "supply_origin = torch.tensor(supply).to(device).reshape(-1,1).float()\n",
    "temp_origin = torch.tensor(temp).to(device).reshape(-1,1).float()\n",
    "output_origin = torch.tensor(output).to(device).reshape(-1,1).float()\n",
    "temp_cur = torch.tensor(temp_cur).to(device).reshape(-1,1).float()\n",
    "\n",
    "delta = torch.tensor(delta).reshape(-1,1).float().to(device)/(max(temp_origin) - min(temp_origin))\n",
    "delta_supply = torch.tensor(delta_supply).reshape(-1,1).float().to(device)/(max(supply_origin) - min(supply_origin))\n",
    "delta_air = torch.tensor(delta_air).reshape(-1,1).float().to(device)/(max(air_origin)- min(air_origin))\n",
    "\n",
    "delta = torch.concat((delta, delta_supply, delta_air), dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d2502-647d-4557-8c53-b0ece4d372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "air = (air_origin - min(air_origin))/(max(air_origin)- min(air_origin))\n",
    "air = air.requires_grad_(True)\n",
    "supply = (supply_origin - min(supply_origin))/(max(supply_origin) - min(supply_origin))\n",
    "supply = supply.requires_grad_(True)\n",
    "temp = (temp_origin - min(temp_origin))/(max(temp_origin) - min(temp_origin))\n",
    "temp = temp.requires_grad_(True)\n",
    "output = (output - min(output))/(max(output) - min(output))\n",
    "output = torch.tensor(output).reshape(-1,1).float().to(device)\n",
    "temp_cur = (temp_cur - min(temp_origin))/(max(temp_origin) - min(temp_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1655f-f99a-4f60-8f81-58e5535bc22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(N: int, N_end: int, temp_cur: torch.Tensor, temp: torch.Tensor, supply: torch.Tensor, air: torch.Tensor, output: torch.Tensor, delta: torch.Tensor):\n",
    "    temp_cur_tr = temp_cur[N:N_end]\n",
    "    temp_tr = temp[N:N_end]\n",
    "    supply_tr = supply[N:N_end]\n",
    "    air_tr = air[N:N_end]\n",
    "    output_tr = output[N:N_end]\n",
    "    delta_tr = delta[N:N_end].requires_grad_(True)\n",
    "    return temp_cur_tr, temp_tr, supply_tr, air_tr, output_tr, delta_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fdd385-814a-4ced-b988-04b39929a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taylor_Net(nn.Module):\n",
    "    def __init__(self, n=1):\n",
    "        super(Taylor_Net, self).__init__()\n",
    "        self.n = n\n",
    "        self.fc1 = nn.Linear(3, 3*self.n)\n",
    "        self.fc2_1 = nn.Linear(self.n, 1)\n",
    "        self.fc2_2 = nn.Linear(self.n, 1)\n",
    "        self.fc2_3 = nn.Linear(self.n, 1)\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        x = torch.cat((x, y, z), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x_1 = self.fc2_1(x[:, 0:self.n].reshape(-1, self.n))\n",
    "        y_1 = self.fc2_2(x[:, self.n:2*self.n].reshape(-1, self.n))\n",
    "        z_1 = self.fc2_3(x[:, 2*self.n:3*self.n].reshape(-1, self.n))\n",
    "        x = torch.cat((x_1, y_1, z_1), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f06fe-af79-409f-aa6e-208f9012a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next(model, temp_cur_t, temp_t, supply_t, air_t, delta_t):\n",
    "    elementwise_product_t = torch.mul(model(temp_t, supply_t, air_t), delta_t)\n",
    "    dot_products_t = torch.sum(elementwise_product_t, dim=1, keepdim=True)\n",
    "    output_temp_t = temp_cur_t + dot_products_t\n",
    "    return output_temp_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2944ad-4137-4f13-8bf3-ec3075fb79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_2(model, temp_cur_t, temp_t, supply_t, air_t, delta_t):\n",
    "    temp_t = temp_t.requires_grad_(True)\n",
    "    supply_t = supply_t.requires_grad_(True)\n",
    "    air_t = air_t.requires_grad_(True)\n",
    "    elementwise_product_t = torch.mul(model(temp_t, supply_t, air_t), delta_t)\n",
    "    c = model(temp_t, supply_t, air_t)\n",
    "    dot_products_t = torch.sum(elementwise_product_t, dim=1, keepdim=True)\n",
    "    output_temp_t = temp_cur_t + dot_products_t\n",
    "    grad_outputs = torch.ones_like(c)[:, 0]\n",
    "    dc_dx_dx = torch.autograd.grad(outputs=c[:, 0], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dx_dy = torch.autograd.grad(outputs=c[:, 0], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dx_dz = torch.autograd.grad(outputs=c[:, 0], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        \n",
    "    dc_dy_dy = torch.autograd.grad(outputs=c[:, 1], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dy_dx = torch.autograd.grad(outputs=c[:, 1], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dy_dz = torch.autograd.grad(outputs=c[:, 1], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "   \n",
    "    dc_dz_dz = torch.autograd.grad(outputs=c[:, 2], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dz_dx = torch.autograd.grad(outputs=c[:, 2], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dz_dy = torch.autograd.grad(outputs=c[:, 2], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "\n",
    "    dx = delta_t[:, 0].reshape(-1,1)\n",
    "    dy = delta_t[:, 1].reshape(-1,1)\n",
    "    dz = delta_t[:, 2].reshape(-1,1)\n",
    "        \n",
    "    t_next = output_temp_t + (dc_dx_dx*dx**2 + dc_dy_dy*dy**2 + dc_dz_dz*dz**2 + (dc_dx_dy + dc_dy_dx)*dx*dy + (dc_dx_dz + dc_dz_dx)*dx*dz + (dc_dy_dz+dc_dz_dy)*dy*dz) / 2\n",
    "    return t_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8211c0-6b99-4357-ac25-69fca9b85f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, temp_cur_tr, temp_tr, supply_tr, air_tr, output_temp_tr, delta_tr, scheduler=None, epochs=20000, patience=1000, threshold=1e-10, print_interval=5000):\n",
    "    prev_loss = float('inf')\n",
    "    no_improvement_counter = 0\n",
    "    loss_array = []\n",
    "    r2_array = []\n",
    "    point = []\n",
    "    last_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train() \n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        elementwise_product = torch.mul(model(temp_tr, supply_tr, air_tr), delta_tr)\n",
    "        term = F.relu(-model(temp_tr, supply_tr, air_tr)[:, 1].reshape(-1,1))\n",
    "        dot_products = torch.sum(elementwise_product, dim=1, keepdim=True)\n",
    "        output = temp_cur_tr + dot_products\n",
    "        alpha = 0.25 \n",
    "        regularized_term = alpha * term.mean()\n",
    "        loss = criterion(output, output_temp_tr) + regularized_term\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        last_loss = loss\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        if epoch % 50 == 0:\n",
    "            loss_array.append(loss.item())\n",
    "            r2_score_val = r2_score(output_temp_tr.to(\"cpu\").detach().numpy(), output.to(\"cpu\").detach().numpy())\n",
    "            r2_array.append(r2_score_val)\n",
    "            point.append(epoch // 50)\n",
    "        if epoch % print_interval == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.9f}')\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            no_improvement_counter += 1\n",
    "        else:\n",
    "            no_improvement_counter = 0 \n",
    "        prev_loss = loss.item()\n",
    "        if no_improvement_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to no significant improvement.')\n",
    "            break\n",
    "        if loss.item() < 0.0000000087022:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to very low loss.')\n",
    "            print(\"min of loss function is\", min(loss_array))\n",
    "            break\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbd0fb-56b3-45dc-b5c9-6dec2a0d2f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "patience = 1000\n",
    "threshold = 1e-15\n",
    "decay_factor = 1.0 \n",
    "decay_step_size = 1000 \n",
    "\n",
    "N_start, N_end = 360, 540\n",
    "Ns_t, Ne_t = 950, 1050\n",
    "Ns_val, Ne_val = 800, 900\n",
    "temp_cur_tr, temp_tr, supply_tr, air_tr, output_tr, delta_tr = data_split(N_start, N_end, temp_cur, temp, supply, air, output, delta)\n",
    "temp_cur_t, temp_t, supply_t, air_t, output_t, delta_t = data_split(Ns_t, Ne_t, temp_cur, temp, supply, air, output, delta)\n",
    "temp_cur_val, temp_val, supply_val, air_val, output_val, delta_val = data_split(Ns_val, Ne_val, temp_cur, temp, supply, air, output, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_1(model_path, model_class, num_predict, device='cpu'):\n",
    "    r2_loop = []\n",
    "    model = model_class(n=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    t_next = calculate_next(model, temp_cur_t[0:-num_predict], temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict], delta_t[0:-num_predict])\n",
    "    r2 = r2_score(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    thresh = 1\n",
    "    delta = t_next - temp_cur_t[0:-num_predict]\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[1:1-num_predict, 1].reshape(-1,1), delta_t[1:1-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    t_next_2 = calculate_next(model, t_next, temp_t[1:1-num_predict], supply_t[1:1-num_predict], air_t[1:1-num_predict], delta)\n",
    "    r2 = r2_score(output_t[1:1-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    delta = t_next_2 - t_next\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[2:2-num_predict, 1].reshape(-1,1), delta_t[2:2-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(2, num_predict):\n",
    "        t_next_3 = calculate_next(model, t_next_2, t_next, supply_t[i:i-num_predict], air_t[i:i-num_predict], delta)\n",
    "        r2 = r2_score(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next_3.to(\"cpu\").detach().numpy())\n",
    "        r2_loop.append(r2)\n",
    "        delta = t_next_3 - t_next_2\n",
    "        delta = torch.clamp(delta, max=thresh, min = -thresh) \n",
    "        if i < num_predict-1:\n",
    "            delta = torch.cat((delta, delta_t[1+i:1+i-num_predict, 1].reshape(-1,1), delta_t[1+i:1+i-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "            t_next = t_next_2\n",
    "            t_next_2 = t_next_3\n",
    "    return r2_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974b7f6-f341-4895-b3d3-e574faaa7bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20000], Loss: 0.005880089\n",
      "Epoch [5001/20000], Loss: 0.000325709\n",
      "Epoch [10001/20000], Loss: 0.000325676\n",
      "Epoch [15001/20000], Loss: 0.000326109\n",
      "0.00030712842\n",
      "Epoch [1/20000], Loss: 0.005620157\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Early stopping at epoch 7151 due to no significant improvement.\n",
      "0.00030382382\n",
      "Epoch [1/20000], Loss: 0.002371625\n",
      "Epoch [5001/20000], Loss: 0.000322318\n",
      "Epoch [10001/20000], Loss: 0.000322350\n",
      "Epoch [15001/20000], Loss: 0.000321841\n",
      "Epoch [1/20000], Loss: 0.059093248\n",
      "Epoch [5001/20000], Loss: 0.000312266\n",
      "Epoch [10001/20000], Loss: 0.000311642\n",
      "Epoch [15001/20000], Loss: 0.000311222\n",
      "0.0002936226\n",
      "Epoch [1/20000], Loss: 0.026893560\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Early stopping at epoch 6514 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.143184066\n",
      "Epoch [5001/20000], Loss: 0.000325868\n",
      "Epoch [10001/20000], Loss: 0.000329483\n",
      "Epoch [15001/20000], Loss: 0.000326275\n",
      "Epoch [1/20000], Loss: 0.074358761\n",
      "Epoch [5001/20000], Loss: 0.000279344\n",
      "Epoch [10001/20000], Loss: 0.000279343\n",
      "Epoch [15001/20000], Loss: 0.000279345\n",
      "0.00029277\n",
      "Epoch [1/20000], Loss: 0.004112876\n",
      "Epoch [5001/20000], Loss: 0.000284273\n",
      "Epoch [10001/20000], Loss: 0.000284252\n",
      "Epoch [15001/20000], Loss: 0.000284246\n",
      "0.00029052337\n",
      "Epoch [1/20000], Loss: 0.006942749\n",
      "Early stopping at epoch 1401 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.008157340\n",
      "Epoch [5001/20000], Loss: 0.000285872\n",
      "Epoch [10001/20000], Loss: 0.000286733\n",
      "Epoch [15001/20000], Loss: 0.000284234\n",
      "Epoch [1/20000], Loss: 0.242930889\n",
      "Epoch [5001/20000], Loss: 0.000304962\n",
      "Epoch [10001/20000], Loss: 0.000305436\n",
      "Epoch [15001/20000], Loss: 0.000313256\n",
      "Epoch [1/20000], Loss: 0.002224422\n",
      "Epoch [5001/20000], Loss: 0.000261647\n",
      "Epoch [10001/20000], Loss: 0.000261631\n",
      "Epoch [15001/20000], Loss: 0.000261645\n",
      "0.00027867535\n",
      "Epoch [1/20000], Loss: 0.002418538\n",
      "Epoch [5001/20000], Loss: 0.000290875\n",
      "Epoch [10001/20000], Loss: 0.000290678\n",
      "Epoch [15001/20000], Loss: 0.000290679\n",
      "Epoch [1/20000], Loss: 0.001125284\n",
      "Early stopping at epoch 1294 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.235182896\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333093\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.002455820\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000284782\n",
      "Epoch [15001/20000], Loss: 0.000284772\n",
      "Epoch [1/20000], Loss: 0.153391823\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.009852512\n",
      "Early stopping at epoch 2967 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.012331940\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333209\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.000796889\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.002542336\n",
      "Epoch [5001/20000], Loss: 0.000263257\n",
      "Epoch [10001/20000], Loss: 0.000263308\n",
      "Epoch [15001/20000], Loss: 0.000263251\n",
      "Epoch [1/20000], Loss: 0.013107631\n",
      "Epoch [5001/20000], Loss: 0.000310623\n",
      "Epoch [10001/20000], Loss: 0.000310443\n",
      "Epoch [15001/20000], Loss: 0.000310443\n",
      "Epoch [1/20000], Loss: 0.001141658\n",
      "Epoch [5001/20000], Loss: 0.000312578\n",
      "Epoch [10001/20000], Loss: 0.000312570\n",
      "Epoch [15001/20000], Loss: 0.000312619\n",
      "Epoch [1/20000], Loss: 0.000927536\n",
      "Epoch [5001/20000], Loss: 0.000284245\n",
      "Epoch [10001/20000], Loss: 0.000284274\n",
      "Epoch [15001/20000], Loss: 0.000284356\n",
      "Epoch [1/20000], Loss: 0.321634114\n",
      "Early stopping at epoch 2079 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.010566034\n",
      "Epoch [5001/20000], Loss: 0.000330044\n",
      "Epoch [10001/20000], Loss: 0.000329909\n",
      "Epoch [15001/20000], Loss: 0.000330060\n",
      "Epoch [1/20000], Loss: 0.004229254\n",
      "Early stopping at epoch 2703 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.251696646\n",
      "Epoch [5001/20000], Loss: 0.000329909\n",
      "Epoch [10001/20000], Loss: 0.000329909\n",
      "Epoch [15001/20000], Loss: 0.000329909\n",
      "Epoch [1/20000], Loss: 0.016846556\n",
      "Early stopping at epoch 3846 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.002344903\n",
      "Epoch [5001/20000], Loss: 0.000284291\n",
      "Epoch [10001/20000], Loss: 0.000284317\n",
      "Epoch [15001/20000], Loss: 0.000284236\n",
      "Epoch [1/20000], Loss: 0.003573410\n",
      "Epoch [5001/20000], Loss: 0.000312570\n",
      "Epoch [10001/20000], Loss: 0.000312571\n",
      "Epoch [15001/20000], Loss: 0.000312575\n",
      "Epoch [1/20000], Loss: 0.068167321\n",
      "Epoch [5001/20000], Loss: 0.000327274\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.100819811\n",
      "Epoch [5001/20000], Loss: 0.000284278\n",
      "Epoch [10001/20000], Loss: 0.000284244\n",
      "Epoch [15001/20000], Loss: 0.000284281\n",
      "Epoch [1/20000], Loss: 0.141136348\n",
      "Epoch [5001/20000], Loss: 0.000313273\n",
      "Epoch [10001/20000], Loss: 0.000313356\n",
      "Epoch [15001/20000], Loss: 0.000313277\n",
      "Epoch [1/20000], Loss: 0.009114073\n",
      "Epoch [5001/20000], Loss: 0.000309514\n",
      "Epoch [10001/20000], Loss: 0.000309552\n",
      "Epoch [15001/20000], Loss: 0.000309474\n",
      "Epoch [1/20000], Loss: 0.003546305\n",
      "Epoch [5001/20000], Loss: 0.000330252\n",
      "Epoch [10001/20000], Loss: 0.000329909\n",
      "Epoch [15001/20000], Loss: 0.000309525\n",
      "Epoch [1/20000], Loss: 0.081164032\n",
      "Early stopping at epoch 1420 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.007446590\n",
      "Early stopping at epoch 1362 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.001395698\n",
      "Epoch [5001/20000], Loss: 0.000284235\n",
      "Epoch [10001/20000], Loss: 0.000284278\n",
      "Epoch [15001/20000], Loss: 0.000284342\n",
      "Epoch [1/20000], Loss: 0.000538318\n",
      "Epoch [5001/20000], Loss: 0.000313334\n",
      "Epoch [10001/20000], Loss: 0.000313276\n",
      "Epoch [15001/20000], Loss: 0.000313551\n",
      "Epoch [1/20000], Loss: 0.002345432\n",
      "Epoch [5001/20000], Loss: 0.000279454\n",
      "Epoch [10001/20000], Loss: 0.000258098\n",
      "Epoch [15001/20000], Loss: 0.000258634\n",
      "Epoch [1/20000], Loss: 0.107882373\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.007310340\n",
      "Epoch [5001/20000], Loss: 0.000284238\n",
      "Epoch [10001/20000], Loss: 0.000284249\n",
      "Epoch [15001/20000], Loss: 0.000284384\n",
      "Epoch [1/20000], Loss: 0.008235415\n",
      "Early stopping at epoch 1359 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.009848257\n",
      "Epoch [5001/20000], Loss: 0.000284401\n",
      "Epoch [10001/20000], Loss: 0.000284671\n",
      "Epoch [15001/20000], Loss: 0.000284373\n",
      "Epoch [1/20000], Loss: 0.108268611\n",
      "Early stopping at epoch 1427 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.010133689\n",
      "Early stopping at epoch 1346 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.238264561\n",
      "Early stopping at epoch 1511 due to no significant improvement.\n",
      "Epoch [1/20000], Loss: 0.193419158\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n",
      "Epoch [1/20000], Loss: 0.001449358\n",
      "Epoch [5001/20000], Loss: 0.000333092\n",
      "Epoch [10001/20000], Loss: 0.000333092\n",
      "Epoch [15001/20000], Loss: 0.000333092\n"
     ]
    }
   ],
   "source": [
    "learning = np.arange(0.001, 0.1, 0.002)\n",
    "num_t = 1\n",
    "current_mse_score = 0\n",
    "mse = []\n",
    "mse.append(1.0)\n",
    "for lr in learning:\n",
    "    # Train model_Taylor\n",
    "    model_Taylor = Taylor_Net().to(device)\n",
    "    optimizer = optim.Adam(model_Taylor.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=decay_step_size, gamma=decay_factor)\n",
    "\n",
    "    loss_Tay = train_model(\n",
    "        model=model_Taylor,\n",
    "        optimizer=optimizer,\n",
    "        criterion=nn.MSELoss(),\n",
    "        temp_cur_tr= temp_cur_tr,\n",
    "        temp_tr=temp_tr,\n",
    "        supply_tr=supply_tr,\n",
    "        air_tr=air_tr,\n",
    "        output_temp_tr=output_tr,\n",
    "        delta_tr=delta_tr,\n",
    "        scheduler=scheduler, \n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        threshold=threshold,\n",
    "        print_interval=5000\n",
    "    )\n",
    "    if loss_Tay < 10.1:\n",
    "            t_next_t = calculate_next(model_Taylor,temp_cur_val, temp_val, supply_val, air_val, delta_val)\n",
    "            current_mse_score = mean_squared_error(output_val.to(\"cpu\").detach().numpy(), t_next_t.to(\"cpu\").detach().numpy())\n",
    "            if current_mse_score > -10:\n",
    "                if current_mse_score < min(mse):\n",
    "                    torch.save(model_Taylor.state_dict(), f\"model_Taylor_1st_loss_5min.pth\")\n",
    "                    mse.append(current_mse_score)\n",
    "                    print(current_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ac6b4-6cf6-41ba-8c6d-a02d94b49a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9806225248689782,\n",
       " 0.9576728348852515,\n",
       " 0.9451736663035405,\n",
       " 0.9173553989941485,\n",
       " 0.903008826649852,\n",
       " 0.8765132044195988,\n",
       " 0.8442818641322198]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_predict = 7\n",
    "\n",
    "model_path = f\"model_Taylor_1st_loss_5min.pth\"\n",
    "\n",
    "model = Taylor_Net().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "t_next = calculate_next(model, temp_cur_t[0:-num_predict], temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict], delta_t[0:-num_predict])\n",
    "plt.plot(t_next.to(\"cpu\").detach().numpy())\n",
    "plt.plot(output_t[:-num_predict].to(\"cpu\").detach().numpy())\n",
    "evaluate_model_1(model_path, model_class=Taylor_Net, num_predict=num_predict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0780b5-06db-4c7a-bb51-5e57220b6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify train_model to accept scheduler\n",
    "def train_model_2(model, optimizer, criterion, temp_cur_tr, temp_tr, supply_tr, air_tr, output_temp_tr, delta_tr, scheduler=None, epochs=20000, patience=1000, threshold=1e-10, print_interval=5000):\n",
    "    prev_loss = float('inf')\n",
    "    no_improvement_counter = 0\n",
    "    loss_array = []\n",
    "    r2_array = []\n",
    "    last_loss = 0\n",
    "    point = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  \n",
    "        optimizer.zero_grad()\n",
    "        elementwise_product = torch.mul(model(temp_tr, supply_tr, air_tr), delta_tr)\n",
    "        c = model(temp_tr, supply_tr, air_tr)\n",
    "        dot_products = torch.sum(elementwise_product, dim=1, keepdim=True)\n",
    "        output = temp_cur_tr + dot_products\n",
    "    \n",
    "        grad_outputs = torch.ones_like(c)[:, 0]\n",
    "\n",
    "        dc_dx_dx = torch.autograd.grad(outputs=c[:, 0], inputs=temp_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dx_dy = torch.autograd.grad(outputs=c[:, 0], inputs=supply_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dx_dz = torch.autograd.grad(outputs=c[:, 0], inputs=air_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        \n",
    "        dc_dy_dy = torch.autograd.grad(outputs=c[:, 1], inputs=supply_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dy_dx = torch.autograd.grad(outputs=c[:, 1], inputs=temp_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dy_dz = torch.autograd.grad(outputs=c[:, 1], inputs=air_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "\n",
    "        \n",
    "        dc_dz_dz = torch.autograd.grad(outputs=c[:, 2], inputs=air_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dz_dx = torch.autograd.grad(outputs=c[:, 2], inputs=temp_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        dc_dz_dy = torch.autograd.grad(outputs=c[:, 2], inputs=supply_tr, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        \n",
    "        length = len(temp_tr)\n",
    "\n",
    "        dx = delta_tr[:, 0].reshape(-1,1)\n",
    "        dy = delta_tr[:, 1].reshape(-1,1)\n",
    "        dz = delta_tr[:, 2].reshape(-1,1)\n",
    "        t_next = output + (dc_dx_dx*dx**2 + dc_dy_dy*dy**2 + dc_dz_dz*dz**2 + (dc_dx_dy + dc_dy_dx)*dx*dy + (dc_dx_dz + dc_dz_dx)*dx*dz + (dc_dy_dz+dc_dz_dy)*dy*dz) / 2\n",
    "        \n",
    "        term = F.relu(-model_Taylor(temp_tr, supply_tr, air_tr)[:, 1].reshape(-1,1))\n",
    "        alpha = 0.25\n",
    "        regularized_term = alpha * term.mean()\n",
    "        \n",
    "        loss = criterion(t_next, output_temp_tr)\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        last_loss = loss\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        if epoch % 50 ==0:\n",
    "            r2_score_val = r2_score(output_temp_tr.to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "            r2_array.append(r2_score_val)\n",
    "            point.append(epoch // 50)\n",
    "        if epoch % print_interval == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.9f}')\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            no_improvement_counter += 1\n",
    "        else:\n",
    "            no_improvement_counter = 0  \n",
    "        prev_loss = loss.item()\n",
    "        if no_improvement_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to no significant improvement.')\n",
    "            break\n",
    "        if loss.item() < 0.0000075052:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to very low loss.')\n",
    "            print(\"min of loss function is\", min(loss_array))\n",
    "            break\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c628a2-83ed-4063-add2-f913d49a08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_2(model, temp_cur_t, temp_t, supply_t, air_t, delta_t):\n",
    "    temp_t = temp_t.requires_grad_(True)\n",
    "    supply_t = supply_t.requires_grad_(True)\n",
    "    air_t = air_t.requires_grad_(True)\n",
    "    elementwise_product_t = torch.mul(model(temp_t, supply_t, air_t), delta_t)\n",
    "    c = model(temp_t, supply_t, air_t)\n",
    "    dot_products_t = torch.sum(elementwise_product_t, dim=1, keepdim=True)\n",
    "    output_temp_t = temp_cur_t + dot_products_t\n",
    "    grad_outputs = torch.ones_like(c)[:, 0]\n",
    "    dc_dx_dx = torch.autograd.grad(outputs=c[:, 0], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dx_dy = torch.autograd.grad(outputs=c[:, 0], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dx_dz = torch.autograd.grad(outputs=c[:, 0], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "        \n",
    "    dc_dy_dy = torch.autograd.grad(outputs=c[:, 1], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dy_dx = torch.autograd.grad(outputs=c[:, 1], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dy_dz = torch.autograd.grad(outputs=c[:, 1], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "   \n",
    "    dc_dz_dz = torch.autograd.grad(outputs=c[:, 2], inputs=air_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dz_dx = torch.autograd.grad(outputs=c[:, 2], inputs=temp_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "    dc_dz_dy = torch.autograd.grad(outputs=c[:, 2], inputs=supply_t, grad_outputs=grad_outputs, retain_graph=True)[0]\n",
    "\n",
    "    dx = delta_t[:, 0].reshape(-1,1)\n",
    "    dy = delta_t[:, 1].reshape(-1,1)\n",
    "    dz = delta_t[:, 2].reshape(-1,1)\n",
    "        \n",
    "    t_next = output_temp_t + (dc_dx_dx*dx**2 + dc_dy_dy*dy**2 + dc_dz_dz*dz**2 + (dc_dx_dy + dc_dy_dx)*dx*dy + (dc_dx_dz + dc_dz_dx)*dx*dz + (dc_dy_dz+dc_dz_dy)*dy*dz) / 2\n",
    "    return t_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85642643-7cf3-4357-a29a-1302720170ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_2(model_path, model_class, num_predict, device='cpu'):\n",
    "    r2_loop = []\n",
    "    model = model_class(n=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    t_next = calculate_next_2(model, temp_cur_t[0:-num_predict], temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict], delta_t[0:-num_predict])\n",
    "    r2 = r2_score(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    thresh = 1\n",
    "    delta = t_next - temp_cur_t[0:-num_predict]\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[1:1-num_predict, 1].reshape(-1,1), delta_t[1:1-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    t_next_2 = calculate_next_2(model, t_next, temp_t[1:1-num_predict], supply_t[1:1-num_predict], air_t[1:1-num_predict], delta)\n",
    "    r2 = r2_score(output_t[1:1-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    delta = t_next_2 - t_next\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[2:2-num_predict, 1].reshape(-1,1), delta_t[2:2-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(2, num_predict):\n",
    "        t_next_3 = calculate_next_2(model, t_next_2, t_next, supply_t[i:i-num_predict], air_t[i:i-num_predict], delta)\n",
    "        r2 = r2_score(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next_3.to(\"cpu\").detach().numpy())\n",
    "        r2_loop.append(r2)\n",
    "        delta = t_next_3 - t_next_2\n",
    "        delta = torch.clamp(delta, max=thresh, min = -thresh) \n",
    "        if i < num_predict-1:\n",
    "            delta = torch.cat((delta, delta_t[1+i:1+i-num_predict, 1].reshape(-1,1), delta_t[1+i:1+i-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "            t_next = t_next_2\n",
    "            t_next_2 = t_next_3\n",
    "    return r2_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35b586-174b-4eee-9fee-a5ae436bcba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning = np.arange(0.0001, 0.01, 0.0002)\n",
    "num_t = 1\n",
    "current_mse_score = 0\n",
    "mse = []\n",
    "mse.append(0.000287086)\n",
    "for lr in learning:\n",
    "    for i in range(num_t):\n",
    "        n_value = 1\n",
    "        model_path = f\"model_Taylor_1st_loss_5min.pth\"\n",
    "        model_Taylor = Taylor_Net(n=n_value).to(device)\n",
    "        model_Taylor.load_state_dict(torch.load(model_path))\n",
    "        optimizer = optim.Adam(model_Taylor.parameters(), lr=lr)\n",
    "        scheduler = StepLR(optimizer, step_size=decay_step_size, gamma=decay_factor)\n",
    "        loss_Tay = train_model_2(\n",
    "            model=model_Taylor,\n",
    "            optimizer=optimizer,\n",
    "            criterion=nn.MSELoss(),\n",
    "            temp_cur_tr= temp_cur_tr,\n",
    "            temp_tr=temp_tr,\n",
    "            supply_tr=supply_tr,\n",
    "            air_tr=air_tr,\n",
    "            output_temp_tr=output_tr,\n",
    "            delta_tr=delta_tr,\n",
    "            scheduler=scheduler,  \n",
    "            epochs=3000,\n",
    "            patience=patience,\n",
    "            threshold=threshold,\n",
    "            print_interval=5000\n",
    "        )\n",
    "        if loss_Tay < 10.1:\n",
    "            t_next_t = calculate_next_2(model_Taylor, temp_cur_val, temp_val, supply_val, air_val, delta_val)\n",
    "            current_mse_score = mean_squared_error(output_val.to(\"cpu\").detach().numpy(), t_next_t.to(\"cpu\").detach().numpy())\n",
    "            if current_mse_score > -10:\n",
    "                if current_mse_score < min(mse):\n",
    "                    torch.save(model_Taylor.state_dict(), f\"model_Taylor_2nd_loss_5_mins.pth\")\n",
    "                    mse.append(current_mse_score)\n",
    "                    print(current_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f32ed2-d957-4a1f-9365-36010423b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9800539143394313,\n",
       " 0.9568989812056183,\n",
       " 0.9437286471587181,\n",
       " 0.916162713301424,\n",
       " 0.9034038067031734,\n",
       " 0.878113599004022,\n",
       " 0.847786032088796]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_predict = 7\n",
    "\n",
    "model_path = f\"model_Taylor_2nd_loss_5_mins.pth\"\n",
    "evaluate_model_2(model_path, model_class=Taylor_Net, num_predict=num_predict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1b7de-3f5b-4db3-b76c-ea7db7f3d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_model_1(model_path, model_class, num_predict, device='cpu'):\n",
    "    r2_loop = []\n",
    "    # Load the model\n",
    "    model = model_class(n=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    # Ensure the test data is the same as when you calculated the r2_score previously\n",
    "    t_next = calculate_next(model, temp_cur_t[0:-num_predict], temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict], delta_t[0:-num_predict])\n",
    "    r2 = mean_squared_error(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    thresh = 1\n",
    "    delta = t_next - temp_cur_t[0:-num_predict]\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[1:1-num_predict, 1].reshape(-1,1), delta_t[1:1-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    t_next_2 = calculate_next(model, t_next, temp_t[1:1-num_predict], supply_t[1:1-num_predict], air_t[1:1-num_predict], delta)\n",
    "    r2 = mean_squared_error(output_t[1:1-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    delta = t_next_2 - t_next\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[2:2-num_predict, 1].reshape(-1,1), delta_t[2:2-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(2, num_predict):\n",
    "        t_next_3 = calculate_next(model, t_next_2, t_next, supply_t[i:i-num_predict], air_t[i:i-num_predict], delta)\n",
    "        r2 = mean_squared_error(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next_3.to(\"cpu\").detach().numpy())\n",
    "        r2_loop.append(r2)\n",
    "        delta = t_next_3 - t_next_2\n",
    "        delta = torch.clamp(delta, max=thresh, min = -thresh) \n",
    "        if i < num_predict-1:\n",
    "            delta = torch.cat((delta, delta_t[1+i:1+i-num_predict, 1].reshape(-1,1), delta_t[1+i:1+i-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "            t_next = t_next_2\n",
    "            t_next_2 = t_next_3\n",
    "    return np.sqrt(r2_loop).reshape(-1,1)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d388eff-e81f-4966-b32c-7dd96abaafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_model_2(model_path, model_class, num_predict, device='cpu'):\n",
    "    r2_loop = []\n",
    "    # Load the model\n",
    "    model = model_class(n=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    # Ensure the test data is the same as when you calculated the r2_score previously\n",
    "    t_next = calculate_next_2(model, temp_cur_t[0:-num_predict], temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict], delta_t[0:-num_predict])\n",
    "    r2 = mean_squared_error(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    thresh = 1\n",
    "    delta = t_next - temp_cur_t[0:-num_predict]\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[1:1-num_predict, 1].reshape(-1,1), delta_t[1:1-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    t_next_2 = calculate_next_2(model, t_next, temp_t[1:1-num_predict], supply_t[1:1-num_predict], air_t[1:1-num_predict], delta)\n",
    "    r2 = mean_squared_error(output_t[1:1-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    delta = t_next_2 - t_next\n",
    "    delta = torch.clamp(delta, max=thresh, min = -thresh)\n",
    "    delta = torch.cat((delta, delta_t[2:2-num_predict, 1].reshape(-1,1), delta_t[2:2-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "    \n",
    "    for i in range(2, num_predict):\n",
    "        t_next_3 = calculate_next_2(model, t_next_2, t_next, supply_t[i:i-num_predict], air_t[i:i-num_predict], delta)\n",
    "        r2 = mean_squared_error(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next_3.to(\"cpu\").detach().numpy())\n",
    "        r2_loop.append(r2)\n",
    "        delta = t_next_3 - t_next_2\n",
    "        delta = torch.clamp(delta, max=thresh, min = -thresh) \n",
    "        if i < num_predict-1:\n",
    "            delta = torch.cat((delta, delta_t[1+i:1+i-num_predict, 1].reshape(-1,1), delta_t[1+i:1+i-num_predict, 2].reshape(-1,1)), dim = 1)\n",
    "            t_next = t_next_2\n",
    "            t_next_2 = t_next_3\n",
    "    return np.sqrt(r2_loop).reshape(-1,1)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1d88a-e012-457a-a987-0971bbe76004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12672868],\n",
       "       [0.18496574],\n",
       "       [0.20852153],\n",
       "       [0.2535883 ],\n",
       "       [0.27227154],\n",
       "       [0.3046829 ],\n",
       "       [0.33958054]], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_predict = 7\n",
    "\n",
    "model_path = f\"model_Taylor_1st_loss_5min.pth\"\n",
    "\n",
    "model = Taylor_Net().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "rmse_model_1(model_path, model_class=Taylor_Net, num_predict=num_predict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c761af-ce1f-4dcf-b72f-c1a78d5c5dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1285746 ],\n",
       "       [0.18664892],\n",
       "       [0.21125157],\n",
       "       [0.25541157],\n",
       "       [0.27171656],\n",
       "       [0.30270213],\n",
       "       [0.33573794]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_predict = 7\n",
    "\n",
    "model_path = f\"model_Taylor_2nd_loss_5_mins.pth\"\n",
    "rmse_model_2(model_path, model_class=Taylor_Net, num_predict=num_predict, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
