{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049edea-42bc-41cb-b06b-a301f634722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72803766-8933-4656-9d85-3d56e77ae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "data = pd.read_csv(\"data-B90102-30m.csv\")\n",
    "room = data[\"room_temp\"]\n",
    "airflow = data[\"airflow_cur\"]\n",
    "supply = data[\"supply_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4e9a6-8461-4f12-9455-cd6eb20bf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delt =  np.array(room[start:-1]) - np.array(room[start-1:-2])\n",
    "delt_supply = np.array(supply[start+1:]) - np.array(supply[start:-1])\n",
    "delt_air = np.array(airflow[start+1:]) - np.array(airflow[start:-1])\n",
    "\n",
    "temp_cur = np.array(room[start:-1]).reshape(-1,1)\n",
    "temp = np.array(room[start:-1]).reshape(-1,1)\n",
    "output = np.array(room[start+1:]).reshape(-1,1)\n",
    "air = np.array(airflow[start+1:]).reshape(-1,1)\n",
    "supply = np.array(supply[start+1:]).reshape(-1,1)\n",
    "\n",
    "air_ori = torch.tensor(air).to(device).reshape(-1,1).float()\n",
    "supply_ori = torch.tensor(supply).to(device).reshape(-1,1).float()\n",
    "temp_ori = torch.tensor(temp).to(device).reshape(-1,1).float()\n",
    "output_ori = torch.tensor(output).to(device).reshape(-1,1).float()\n",
    "temp_cur = torch.tensor(temp_cur).to(device).reshape(-1,1).float()\n",
    "\n",
    "delt = torch.tensor(delt).reshape(-1,1).float().to(device)/(max(temp_ori) - min(temp_ori))\n",
    "delt_supply = torch.tensor(delt_supply).reshape(-1,1).float().to(device)/(max(supply_ori) - min(supply_ori))\n",
    "delt_air = torch.tensor(delt_air).reshape(-1,1).float().to(device)/(max(air_ori)- min(air_ori))\n",
    "delt = torch.concat((delt, delt_supply, delt_air), dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28d502-e17c-47fa-b419-d679b5e4a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "air = (air_ori - min(air_ori))/(max(air_ori)- min(air_ori))\n",
    "air = air.requires_grad_(True)\n",
    "supply = (supply_ori - min(supply_ori))/(max(supply_ori) - min(supply_ori))\n",
    "supply = supply.requires_grad_(True)\n",
    "temp = (temp_ori - min(temp_ori))/(max(temp_ori) - min(temp_ori))\n",
    "temp = temp.requires_grad_(True)\n",
    "output = (output - min(output))/(max(output) - min(output))\n",
    "output = torch.tensor(output).reshape(-1,1).float().to(device)\n",
    "temp_cur = (temp_cur - min(temp_ori))/(max(temp_ori) - min(temp_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47096e9d-7a73-4abf-b109-b637c65d9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(N: int, N_end: int, temp_cur: torch.Tensor, temp: torch.Tensor, supply: torch.Tensor, air: torch.Tensor, output: torch.Tensor, delt: torch.Tensor):\n",
    "    temp_cur_tr = temp_cur[N:N_end]\n",
    "    temp_tr = temp[N:N_end]\n",
    "    supply_tr = supply[N:N_end]\n",
    "    air_tr = air[N:N_end]\n",
    "    output_tr = output[N:N_end]\n",
    "    delt_tr = delt[N:N_end].requires_grad_(True)\n",
    "    return temp_cur_tr, temp_tr, supply_tr, air_tr, output_tr, delt_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1e7b0a-75e5-48f4-a71d-bb540c2f652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Base_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        x = torch.cat((x, y, z), dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model_Base = Base_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eea1f8-c425-403e-bc86-781d1ad5a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, temp_tr, supply_tr, air_tr, output_tr, delt_tr, scheduler=None, epochs=20000, patience=1000, threshold=1e-10, print_interval=5000):\n",
    "    prev_loss = float('inf')\n",
    "    no_improvement_counter = 0\n",
    "    loss_array = []\n",
    "    last_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  \n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        output = model(temp_tr, supply_tr, air_tr)\n",
    "        loss = criterion(output, output_tr)\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        last_loss = loss\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        if epoch % print_interval == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.9f}')\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            no_improvement_counter += 1\n",
    "        else:\n",
    "            no_improvement_counter = 0  \n",
    "        prev_loss = loss.item()\n",
    "        if no_improvement_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to no significant improvement.')\n",
    "            break\n",
    "        if loss.item() < 0.00000000087022:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to very low loss.')\n",
    "            print(\"min of loss function is\", min(loss_array))\n",
    "            break\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86677811-d89d-43a2-9459-5dd8eb0c5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25000\n",
    "patience = 1000\n",
    "threshold = 1e-15\n",
    "decay_factor = 1.0  \n",
    "decay_step_size = 1000  \n",
    "N_start, N_end = 360, 540\n",
    "Ns_t, Ne_t = 950, 1050\n",
    "Ns_val, Ne_val = 800, 900\n",
    "temp_cur_tr, temp_tr, supply_tr, air_tr, output_tr, delt_tr = data_split(N_start, N_end, temp_cur, temp, supply, air, output, delt)\n",
    "temp_cur_t, temp_t, supply_t, air_t, output_t, delt_t = data_split(Ns_t, Ne_t, temp_cur, temp, supply, air, output, delt)\n",
    "temp_cur_val, temp_val, supply_val, air_val, output_val, delt_val = data_split(Ns_val, Ne_val, temp_cur, temp, supply, air, output, delt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55434a-9272-4e99-8729-63056f6de649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25000], Loss: 0.059127338\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "0.0002998158\n",
      "Epoch [1/25000], Loss: 0.030136772\n",
      "Early stopping at epoch 1274 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.824278593\n",
      "Early stopping at epoch 3668 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.118512243\n",
      "Epoch [5001/25000], Loss: 0.000262773\n",
      "Epoch [10001/25000], Loss: 0.000262773\n",
      "Epoch [15001/25000], Loss: 0.000262773\n",
      "Epoch [20001/25000], Loss: 0.000262773\n",
      "0.00029576398\n",
      "Epoch [1/25000], Loss: 0.018264063\n",
      "Epoch [5001/25000], Loss: 0.000265873\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.053125404\n",
      "Epoch [5001/25000], Loss: 0.000262773\n",
      "Epoch [10001/25000], Loss: 0.000262773\n",
      "Epoch [15001/25000], Loss: 0.000262773\n",
      "Epoch [20001/25000], Loss: 0.000262775\n",
      "Epoch [1/25000], Loss: 0.140967354\n",
      "Early stopping at epoch 3576 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.134066463\n",
      "Early stopping at epoch 1290 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.207489446\n",
      "Epoch [5001/25000], Loss: 0.000267421\n",
      "Early stopping at epoch 7095 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.126575589\n",
      "Early stopping at epoch 1293 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.237733260\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Early stopping at epoch 5116 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.071850874\n",
      "Early stopping at epoch 1311 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.206323370\n",
      "Early stopping at epoch 1315 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.050788283\n",
      "Early stopping at epoch 1288 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.211673215\n",
      "Epoch [5001/25000], Loss: 0.000262778\n",
      "Epoch [10001/25000], Loss: 0.000262781\n",
      "Epoch [15001/25000], Loss: 0.000262773\n",
      "Epoch [20001/25000], Loss: 0.000262774\n",
      "Epoch [1/25000], Loss: 0.061723672\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265874\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265924\n",
      "Epoch [1/25000], Loss: 0.719277143\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265902\n",
      "Epoch [20001/25000], Loss: 0.000270781\n",
      "Epoch [1/25000], Loss: 0.195562407\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Early stopping at epoch 5289 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.057084870\n",
      "Early stopping at epoch 1302 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.178217873\n",
      "Early stopping at epoch 1296 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.527617216\n",
      "Early stopping at epoch 3964 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.091905296\n",
      "Epoch [5001/25000], Loss: 0.000265866\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000358159\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.106193632\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265865\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.072201125\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.065179318\n",
      "Epoch [5001/25000], Loss: 0.000265880\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000270291\n",
      "Epoch [1/25000], Loss: 0.224223673\n",
      "Early stopping at epoch 1313 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.037195180\n",
      "Epoch [5001/25000], Loss: 0.000267294\n",
      "Epoch [10001/25000], Loss: 0.000297746\n",
      "Epoch [15001/25000], Loss: 0.000302206\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.036992986\n",
      "Epoch [5001/25000], Loss: 0.000276486\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265865\n",
      "Epoch [20001/25000], Loss: 0.000281425\n",
      "Epoch [1/25000], Loss: 0.053983513\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000347511\n",
      "Epoch [20001/25000], Loss: 0.000265864\n",
      "Epoch [1/25000], Loss: 0.232882440\n",
      "Early stopping at epoch 1306 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.346091092\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265864\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265867\n",
      "Epoch [1/25000], Loss: 0.062618755\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265909\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000265902\n",
      "Epoch [1/25000], Loss: 0.107347086\n",
      "Epoch [5001/25000], Loss: 0.000262793\n",
      "Epoch [10001/25000], Loss: 0.000262773\n",
      "Epoch [15001/25000], Loss: 0.000262774\n",
      "Epoch [20001/25000], Loss: 0.000262773\n",
      "Epoch [1/25000], Loss: 0.053774014\n",
      "Epoch [5001/25000], Loss: 0.000265867\n",
      "Epoch [10001/25000], Loss: 0.000265893\n",
      "Epoch [15001/25000], Loss: 0.000265864\n",
      "Epoch [20001/25000], Loss: 0.000266337\n",
      "Epoch [1/25000], Loss: 0.557323337\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000265889\n",
      "Epoch [15001/25000], Loss: 0.000266128\n",
      "Epoch [20001/25000], Loss: 0.000265866\n",
      "Epoch [1/25000], Loss: 0.049837507\n",
      "Epoch [5001/25000], Loss: 0.000228903\n",
      "Epoch [10001/25000], Loss: 0.000230037\n",
      "Epoch [15001/25000], Loss: 0.000241510\n",
      "Epoch [20001/25000], Loss: 0.000228398\n",
      "0.00024414703\n",
      "Epoch [1/25000], Loss: 0.052675944\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000269982\n",
      "Epoch [15001/25000], Loss: 0.000266118\n",
      "Epoch [20001/25000], Loss: 0.000265865\n",
      "Epoch [1/25000], Loss: 0.028681703\n",
      "Epoch [5001/25000], Loss: 0.000240642\n",
      "Epoch [10001/25000], Loss: 0.000262556\n",
      "Epoch [15001/25000], Loss: 0.000236739\n",
      "Epoch [20001/25000], Loss: 0.000236533\n",
      "Epoch [1/25000], Loss: 0.317406863\n",
      "Early stopping at epoch 2162 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.045775175\n",
      "Epoch [5001/25000], Loss: 0.000262773\n",
      "Epoch [10001/25000], Loss: 0.000477277\n",
      "Epoch [15001/25000], Loss: 0.000262782\n",
      "Epoch [20001/25000], Loss: 0.000263229\n",
      "Epoch [1/25000], Loss: 0.076353855\n",
      "Epoch [5001/25000], Loss: 0.000230075\n",
      "Epoch [10001/25000], Loss: 0.000295720\n",
      "Epoch [15001/25000], Loss: 0.000253274\n",
      "Epoch [20001/25000], Loss: 0.000236402\n",
      "Epoch [1/25000], Loss: 0.041982360\n",
      "Epoch [5001/25000], Loss: 0.000266859\n",
      "Epoch [10001/25000], Loss: 0.000265892\n",
      "Epoch [15001/25000], Loss: 0.000268508\n",
      "Epoch [20001/25000], Loss: 0.000269678\n",
      "Epoch [1/25000], Loss: 0.030331474\n",
      "Epoch [5001/25000], Loss: 0.017670516\n",
      "Epoch [10001/25000], Loss: 0.017703054\n",
      "Epoch [15001/25000], Loss: 0.017670516\n",
      "Epoch [20001/25000], Loss: 0.017670516\n",
      "Epoch [1/25000], Loss: 0.581693530\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000434045\n",
      "Epoch [15001/25000], Loss: 0.000290601\n",
      "Epoch [20001/25000], Loss: 0.000267090\n",
      "Epoch [1/25000], Loss: 0.373449117\n",
      "Epoch [5001/25000], Loss: 0.017670516\n",
      "Early stopping at epoch 6050 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.172268406\n",
      "Epoch [5001/25000], Loss: 0.000493170\n",
      "Epoch [10001/25000], Loss: 0.000240397\n",
      "Epoch [15001/25000], Loss: 0.000375888\n",
      "Epoch [20001/25000], Loss: 0.000263522\n",
      "Epoch [1/25000], Loss: 0.830528438\n",
      "Epoch [5001/25000], Loss: 0.000265864\n",
      "Epoch [10001/25000], Loss: 0.000266312\n",
      "Epoch [15001/25000], Loss: 0.000300839\n",
      "Epoch [20001/25000], Loss: 0.000266643\n",
      "Epoch [1/25000], Loss: 0.077773631\n",
      "Epoch [5001/25000], Loss: 0.000262963\n",
      "Epoch [10001/25000], Loss: 0.000270094\n",
      "Epoch [15001/25000], Loss: 0.000272512\n",
      "Epoch [20001/25000], Loss: 0.000266398\n",
      "Epoch [1/25000], Loss: 0.158016235\n",
      "Early stopping at epoch 1309 due to no significant improvement.\n",
      "Epoch [1/25000], Loss: 0.178478584\n",
      "Early stopping at epoch 1401 due to no significant improvement.\n"
     ]
    }
   ],
   "source": [
    "learning = np.arange(0.001, 0.1, 0.002)\n",
    "num_t = 1\n",
    "current_mse_score = 0\n",
    "mse = []\n",
    "mse.append(10.0)\n",
    "prev_loss = 10\n",
    "for lr in learning:\n",
    "    model_Base = Base_Net().to(device)\n",
    "    optimizer = optim.Adam(model_Base.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=decay_step_size, gamma=decay_factor)\n",
    "\n",
    "    loss_Tay = train_model(\n",
    "        model=model_Base,\n",
    "        optimizer=optimizer,\n",
    "        criterion=nn.MSELoss(),\n",
    "        temp_tr=temp_tr,\n",
    "        supply_tr=supply_tr,\n",
    "        air_tr=air_tr,\n",
    "        output_tr=output_tr,\n",
    "        delt_tr=delt_tr,\n",
    "        scheduler=scheduler,  \n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        threshold=threshold,\n",
    "        print_interval=5000\n",
    "    )\n",
    "    if loss_Tay < 10.1:\n",
    "        t_next_t = model_Base(temp_val, supply_val, air_val)\n",
    "        current_mse_score = mean_squared_error(output_val.to(\"cpu\").detach().numpy(), t_next_t.to(\"cpu\").detach().numpy())\n",
    "        if current_mse_score < min(mse):\n",
    "            torch.save(model_Base.state_dict(), f\"model_Base_t_5_min_HVAC.pth\")\n",
    "            mse.append(current_mse_score)\n",
    "            print(current_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88e39f-b595-4e19-9034-5198f6a01348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, model_class, num_predict, device='cpu'):\n",
    "    r2_loop = []\n",
    "    mse_loop = []\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    t_next = model(temp_t[0:-num_predict], supply_t[0:-num_predict], air_t[0:-num_predict])\n",
    "    r2 = r2_score(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    mse = mean_squared_error(output_t[:-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "    r2_loop.append(r2)\n",
    "    mse_loop.append(mse)\n",
    "    for i in range(1, num_predict):\n",
    "        t_next = model(t_next, supply_t[i:i-num_predict], air_t[i:i-num_predict])\n",
    "        r2 = r2_score(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "        mse = mean_squared_error(output_t[i:i-num_predict].to(\"cpu\").detach().numpy(), t_next.to(\"cpu\").detach().numpy())\n",
    "        r2_loop.append(r2)\n",
    "        mse_loop.append(mse)\n",
    "    return r2_loop, mse_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb60e65-f94e-4d83-99d4-87b7a611c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303\n",
      "0.794\n",
      "0.627\n",
      "0.4507\n",
      "0.2858\n",
      "0.1286\n",
      "-0.0067\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "results_1, results_2 = evaluate_model(model_path=f\"model_Base_t_5_min_HVAC.pth\", model_class=Base_Net, num_predict=7, device=device)\n",
    "for value in results_1:\n",
    "    print(value.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f48a4fb-8c99-4dc0-8e05-2e30e37b05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24028\n",
      "0.40807\n",
      "0.5439\n",
      "0.65378\n",
      "0.73881\n",
      "0.80937\n",
      "0.86343\n"
     ]
    }
   ],
   "source": [
    "for value in results_2:\n",
    "    print((np.sqrt(value)*7).round(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
